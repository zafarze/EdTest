import os
import json
import base64
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
from pypdf import PdfReader
import docx
from django.db.models import Avg

# üî• –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à –Ω–æ–≤—ã–π –º–æ–∑–≥ (Brain Center)
# –ü–æ—Å–∫–æ–ª—å–∫—É –æ–±–∞ —Ñ–∞–π–ª–∞ –ª–µ–∂–∞—Ç –≤ –ø–∞–ø–∫–µ services, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç
from .prompt_service import PromptService

# --- 1. –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø ---
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
# –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø—É—Ç–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–æ –æ–±—ã—á–Ω–æ .env –≤ –∫–æ—Ä–Ω–µ
env_path = os.path.join(BASE_DIR, '.env')

load_dotenv(env_path)
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)


# -------------------------------------------------------------------------
# 2. –ü–ê–†–°–ò–ù–ì –§–ê–ô–õ–û–í (–¢–µ–ø–µ—Ä—å —Ç–æ–∂–µ —á–µ—Ä–µ–∑ PromptService!)
# -------------------------------------------------------------------------
def parse_file_with_ai(file_obj, filename):
    print(f"\nüìÇ [AI Service] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {filename}")
    if not client.api_key:
        print("‚ùå –û—à–∏–±–∫–∞: API –∫–ª—é—á OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return []

    text_content = ""
    image_content = None
    ext = filename.split('.')[-1].lower()

    try:
        if ext == 'pdf':
            reader = PdfReader(file_obj)
            for page in reader.pages:
                text_content += page.extract_text() + "\n"
        elif ext in ['docx', 'doc']:
            doc = docx.Document(file_obj)
            para_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
            text_content += para_text + "\n"
            table_text = ""
            for table in doc.tables:
                for row in table.rows:
                    row_data = [cell.text.strip() for cell in row.cells if cell.text.strip()]
                    if row_data: table_text += " | ".join(row_data) + "\n"
            text_content += table_text
        elif ext in ['jpg', 'jpeg', 'png', 'webp']:
            file_obj.seek(0)
            encoded_image = base64.b64encode(file_obj.read()).decode('utf-8')
            image_content = {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}
            }
        else:
            return []
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return []

    if not text_content.strip() and not image_content: return []
    
    # üî• –ò–°–ü–û–õ–¨–ó–£–ï–ú PROMPT SERVICE (Slug: file_parser)
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥–∞–µ–º –ø—É—Å—Ç—ã–º, —Ç–∞–∫ –∫–∞–∫ –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ–±–∞–≤–ª—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –Ω–∏–∂–µ
    messages, config = PromptService.format_messages("file_parser", {})
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Ñ–∞–π–ª–∞ –≤—Ä—É—á–Ω—É—é –≤ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_payload = []
    if text_content: 
        user_payload.append({"type": "text", "text": f"–¢–µ–∫—Å—Ç —Ñ–∞–π–ª–∞:\n{text_content[:25000]}"})
    if image_content: 
        user_payload.append(image_content)
    
    # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º user message, —Ç–∞–∫ –∫–∞–∫ –∫–æ–Ω—Ç–µ–Ω—Ç —Å–ª–æ–∂–Ω—ã–π (—Ç–µ–∫—Å—Ç + —Ñ–æ—Ç–æ)
    # messages[0] - —ç—Ç–æ system, messages[1] - —ç—Ç–æ user (—à–∞–±–ª–æ–Ω –∏–∑ PromptService)
    # –ú—ã –∑–∞–º–µ–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç user message –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    messages[1]["content"] = user_payload

    try:
        response = client.chat.completions.create(
            model=config['model'],
            messages=messages,
            response_format={"type": "json_object"},
            temperature=config['temp']
        )
        data = json.loads(response.choices[0].message.content)
        if "questions" in data: return data["questions"]
        elif isinstance(data, list): return data
        return []
    except Exception as e:
        print(f"‚ùå AI Parsing Error: {e}")
        return []


# -------------------------------------------------------------------------
# üî• 3. –ê–ù–ê–õ–ò–ó –í–û–ü–†–û–°–ê (–°–£–ü–ï–†-–ú–û–ó–ì + –ó–†–ï–ù–ò–ï)
# -------------------------------------------------------------------------
def analyze_question_ai(text, choices, image_file=None):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç: –§–∞–∫—Ç—ã, –ó—Ä–µ–Ω–∏–µ, –ì—Ä–∞–º–º–∞—Ç–∏–∫—É.
    –õ–æ–≥–∏–∫–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤ PromptService (Slug: question_audit).
    """
    print(f"\nüßê [AI AUDIT] –ü—Ä–æ–≤–µ—Ä–∫–∞: '{text[:30]}...'")

    if not client.api_key:
        return {"valid": True, "message": "API Key not found."}

    # 1. –ì–æ—Ç–æ–≤–∏–º —Ç–µ–∫—Å—Ç –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    choices_str = "\n".join([
        f"- {c.get('text', '')} {'(CORRECT)' if c.get('is_correct') else ''}" 
        for c in choices
    ])

    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —à–∞–±–ª–æ–Ω–∞
    context = {
        "text": text,
        "choices": choices_str
    }

    # 3. –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ "–ú–æ–∑–≥–æ–≤–æ–≥–æ –¶–µ–Ω—Ç—Ä–∞"
    messages, config = PromptService.format_messages("question_audit", context)

    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    # –ö–∞—Ä—Ç–∏–Ω–∫—É –Ω–µ–ª—å–∑—è –≤—Å—Ç–∞–≤–∏—Ç—å –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —à–∞–±–ª–æ–Ω {image}, –ø–æ—ç—Ç–æ–º—É –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –Ω–∞—Ç–∏–≤–Ω–æ –≤ API
    if image_file:
        try:
            image_file.seek(0)
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            image_payload = {
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
            }
            
            # user message –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ–¥ –∏–Ω–¥–µ–∫—Å–æ–º 1
            # –ï—Å–ª–∏ —Ç–∞–º –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∞ (–æ—Ç —à–∞–±–ª–æ–Ω–∞), –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –µ—ë –≤ —Å–ø–∏—Å–æ–∫ content
            current_content = messages[1]["content"]
            if isinstance(current_content, str):
                messages[1]["content"] = [
                    {"type": "text", "text": current_content},
                    image_payload
                ]
            elif isinstance(current_content, list):
                messages[1]["content"].append(image_payload)
                
            print("üì∏ –ö–∞—Ä—Ç–∏–Ω–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∫ –∞–Ω–∞–ª–∏–∑—É")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

    # 5. –í—ã–∑–æ–≤ API
    try:
        response = client.chat.completions.create(
            model=config['model'], # GPT-4o –∏–ª–∏ —á—Ç–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –≤ –∞–¥–º–∏–Ω–∫–µ
            messages=messages,
            response_format={"type": "json_object"},
            temperature=config['temp'] # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏–∑ –∞–¥–º–∏–Ω–∫–∏
        )
        
        result = json.loads(response.choices[0].message.content)
        print(f"‚úÖ [AI RESULT]: {result}")
        return result

    except Exception as e:
        print(f"‚ùå AI Error: {e}")
        return {"valid": True, "message": f"–°–±–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ AI: {str(e)}"}


# -------------------------------------------------------------------------
# 4. –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ò–°–¢–†–ê–ö–¢–û–†–û–í
# -------------------------------------------------------------------------
def generate_distractors_ai(question_text, correct_answer):
    if not client.api_key: return ["Error", "No", "Key"]
    
    # 1. –ö–æ–Ω—Ç–µ–∫—Å—Ç
    context = {
        "text": question_text,
        "answer": correct_answer
    }
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç (Slug: distractor_gen)
    messages, config = PromptService.format_messages("distractor_gen", context)

    try:
        response = client.chat.completions.create(
            model=config['model'],
            messages=messages,
            response_format={"type": "json_object"},
            temperature=config['temp']
        )
        data = json.loads(response.choices[0].message.content)
        return data.get("distractors", [])[:3]
    except Exception as e:
        print(f"Distractor Gen Error: {e}")
        return ["–û—à–∏–±–∫–∞", "–ì–µ–Ω–µ—Ä–∞—Ü–∏–∏", "AI"]


# -------------------------------------------------------------------------
# 5. –û–¢–ß–ï–¢ –ü–û –ö–õ–ê–°–°–£
# -------------------------------------------------------------------------
def generate_class_report(exam_id):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–∏—à–µ—Ç –æ—Ç—á–µ—Ç —É—á–∏—Ç–µ–ª—é.
    """
    # –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
    from ..models import Exam, ExamResult
    
    if not client.api_key: return "–û—à–∏–±–∫–∞: AI –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."

    try:
        exam = Exam.objects.get(id=exam_id)
        results = ExamResult.objects.filter(exam=exam)
        total_students = results.count()

        if total_students < 1:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_score_val = results.aggregate(Avg('percentage'))['percentage__avg'] or 0
        
        exam_topic = "–û–±—â–∏–π —ç–∫–∑–∞–º–µ–Ω"
        if exam.questions.exists() and exam.questions.first().topic:
            exam_topic = exam.questions.first().topic.title

        # 1. –ö–æ–Ω—Ç–µ–∫—Å—Ç
        context = {
            "topic": exam_topic,
            "count": total_students,
            "avg": f"{avg_score_val:.1f}"
        }

        # 2. –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç (Slug: class_report)
        # –ï—Å–ª–∏ –≤ –±–∞–∑–µ –Ω–µ—Ç –ø—Ä–æ–º–ø—Ç–∞ 'class_report', –¥–æ–±–∞–≤—å –µ–≥–æ –≤ DEFAULTS PromptService!
        messages, config = PromptService.format_messages("class_report", context)

        response = client.chat.completions.create(
            model=config['model'],
            messages=messages,
            temperature=config['temp']
        )
        
        return response.choices[0].message.content

    except Exception as e:
        print(f"Report Error: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}"