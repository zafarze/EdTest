import cv2
import numpy as np
import json
from ..models import Student, Exam, ExamResult

class GraderService:
    
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (–ø–æ–¥–±–∏—Ä–∞–ª –ø–æ–¥ A4 –∏ —Ç–≤–æ–∏ —è–∫–æ—Ä—è)
    A4_WIDTH_PX = 1240   # –®–∏—Ä–∏–Ω–∞, –∫ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–∏–≤–æ–¥–∏–º —Å–∫–∞–Ω
    A4_HEIGHT_PX = 1754  # –í—ã—Å–æ—Ç–∞ A4 –ø—Ä–∏ 150 DPI
    
    # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–æ–≤ —è–∫–æ—Ä–µ–π –Ω–∞ –∏–¥–µ–∞–ª—å–Ω–æ–º –ª–∏—Å—Ç–µ (–≤ PDF –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –≤ –ø–∏–∫—Å–µ–ª–∏)
    # PDF: A4 (595x842 pt). –Ø–∫–æ—Ä—è: (30,30), (W-40,30), (30, H-40). QR: (W-80, H-80).
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏—Ö –∫ 1240x1754
    SCALE = A4_WIDTH_PX / 595.27
    
    # –¶–µ–ª–µ–≤—ã–µ —Ç–æ—á–∫–∏ (–∫—É–¥–∞ –º—ã —Ö–æ—Ç–∏–º –ø—Ä–∏—Ç—è–Ω—É—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã)
    # –ü–æ—Ä—è–¥–æ–∫: [Top-Left, Top-Right (QR), Bottom-Right, Bottom-Left]
    DST_PTS = np.array([
        [35 * SCALE, 35 * SCALE],                # TL (–Ø–∫–æ—Ä—å –í–µ—Ä—Ö-–õ–µ–≤–æ)
        [515 * SCALE, 80 * SCALE],               # TR (–¶–µ–Ω—Ç—Ä QR-–∫–æ–¥–∞)
        [560 * SCALE, 1719 * SCALE],             # BR (–Ø–∫–æ—Ä—å –ù–∏–∑-–ü—Ä–∞–≤–æ)
        [35 * SCALE, 1719 * SCALE]               # BL (–Ø–∫–æ—Ä—å –ù–∏–∑-–õ–µ–≤–æ)
    ], dtype="float32")

    @staticmethod
    def process_scan(file_obj):
        try:
            # 1. –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –≤ OpenCV
            file_bytes = np.frombuffer(file_obj.read(), np.uint8)
            original_image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

            if original_image is None: 
                return {"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."}

            print("üì∏ [1] –§–æ—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –ù–∞—á–∏–Ω–∞—é –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ...")

            # 2. –í–´–†–ê–í–ù–ò–í–ê–ù–ò–ï (Perspective Transform)
            aligned_image, debug_align_path = GraderService.align_image(original_image)
            
            # –ï—Å–ª–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º (–Ω–∞ —Å—Ç—Ä–∞—Ö –∏ —Ä–∏—Å–∫)
            image_to_scan = aligned_image if aligned_image is not None else original_image

            # 3. –ò—â–µ–º QR-–∫–æ–¥ (—Ç–µ–ø–µ—Ä—å –Ω–∞ —Ä–æ–≤–Ω–æ–º —Ñ–æ—Ç–æ —ç—Ç–æ –ª–µ–≥—á–µ)
            qr_data, _ = GraderService.find_qr_code(image_to_scan)
            
            if not qr_data: 
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–∞ —Ä–æ–≤–Ω–æ–º, –ø—Ä–æ–±—É–µ–º –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ (–≤–¥—Ä—É–≥ –ø—Ä–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏ –æ–±—Ä–µ–∑–∞–ª–∏)
                qr_data, _ = GraderService.find_qr_code(original_image)
                if not qr_data:
                    return {"status": "error", "message": "QR-–∫–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ç–æ —á–µ—Ç–∫–æ–µ."}

            try:
                data = json.loads(qr_data)
                student = Student.objects.get(id=data.get('uid'))
                exam = Exam.objects.get(id=data.get('eid'))
            except Exception:
                return {"status": "error", "message": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ QR-–∫–æ–¥–µ."}

            # 4. –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –û–¢–í–ï–¢–û–í
            print(f"üëÄ [2] –°–∫–∞–Ω–∏—Ä—É—é –æ—Ç–≤–µ—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞: {student.last_name_ru}")
            # –ë–µ—Ä–µ–º –∫–æ–ª-–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ —ç–∫–∑–∞–º–µ–Ω–∞, –∏–ª–∏ 20 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            q_count = exam.questions.count() or 20
            
            student_answers, debug_scan_path = GraderService.recognize_answers(image_to_scan, q_count)
            print(f"‚úÖ [3] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤: {len(student_answers)}")

            # 5. –†–ê–°–ß–ï–¢ –ò –°–û–•–†–ê–ù–ï–ù–ò–ï
            result_obj = GraderService.calculate_and_save(student, exam, student_answers)

            return {
                "status": "success",
                "message": f"–û—Ü–µ–Ω–∫–∞: {result_obj.score} –∏–∑ {result_obj.max_score}",
                "data": {
                    "student": f"{student.last_name_ru} {student.first_name_ru}",
                    "exam": exam.title,
                    "score": result_obj.score,
                    "percent": result_obj.percentage,
                    "debug_files": [debug_align_path, debug_scan_path]
                }
            }

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return {"status": "error", "message": f"–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"}

    @staticmethod
    def align_image(image):
        """
        –ò—â–µ—Ç 3 –∫–≤–∞–¥—Ä–∞—Ç–∞ –∏ QR –∫–æ–¥, –≤—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ª–∏—Å—Ç.
        """
        try:
            # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
            ratio = image.shape[0] / 800.0
            small = cv2.resize(image, (int(image.shape[1] / ratio), 800))
            
            gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edged = cv2.Canny(blurred, 50, 200)

            # –ò—â–µ–º –∫–æ–Ω—Ç—É—Ä—ã
            cnts, _ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            
            anchors = []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã, –∏—â–µ–º –∫–≤–∞–¥—Ä–∞—Ç—ã
            for c in cnts:
                peri = cv2.arcLength(c, True)
                approx = cv2.approxPolyDP(c, 0.04 * peri, True)

                # –Ø–∫–æ—Ä—å –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å 4 —É–≥–ª–∞
                if len(approx) == 4:
                    (x, y, w, h) = cv2.boundingRect(approx)
                    ar = w / float(h)
                    
                    # –§–∏–ª—å—Ç—Ä—ã: —Ä–∞–∑–º–µ—Ä (–Ω–µ —à—É–º –∏ –Ω–µ –≤–µ—Å—å –ª–∏—Å—Ç) –∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ—Å—Ç—å (0.8-1.2)
                    if w > 10 and h > 10 and 0.8 <= ar <= 1.2:
                        anchors.append(approx)

            # –ù–∞–º –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ 3 –∫–≤–∞–¥—Ä–∞—Ç–∞ (—è–∫–æ—Ä—è). QR –∫–æ–¥ –º—ã –Ω–∞–π–¥–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–º.
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤, –±–µ—Ä–µ–º —Å–∞–º—ã–µ –ø–æ—Ö–æ–∂–∏–µ –ø–æ –ø–ª–æ—â–∞–¥–∏
            anchors = sorted(anchors, key=cv2.contourArea, reverse=True)[:5] 
            
            # –ò—â–µ–º QR-–∫–æ–¥ –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            detector = cv2.QRCodeDetector()
            decoded_info, qr_points, _ = detector.detectAndDecode(small)
            
            qr_center = None
            if qr_points is not None:
                # qr_points - —ç—Ç–æ –º–∞—Å—Å–∏–≤ —É–≥–ª–æ–≤ [[x,y], ...]
                pts = qr_points[0]
                center_x = np.mean([p[0] for p in pts])
                center_y = np.mean([p[1] for p in pts])
                qr_center = np.array([center_x, center_y])
            
            # –ï—Å–ª–∏ –Ω–µ—Ç QR –∏–ª–∏ –Ω–µ—Ç —Ö–æ—Ç—è –±—ã 3 –∫–≤–∞–¥—Ä–∞—Ç–æ–≤, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ
            # (–ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —É—Å–ª–æ–∂–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É, –Ω–æ –ø–æ–∫–∞ –≤–µ—Ä–Ω–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª)
            if qr_center is None or len(anchors) < 3:
                print("‚ö†Ô∏è –ù–µ –Ω–∞—à–µ–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —è–∫–æ—Ä–µ–π –∏–ª–∏ QR. –ü—Ä–æ–ø—É—Å–∫–∞—é –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ.")
                return None, None

            # --- –õ–û–ì–ò–ö–ê –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ö–¢–û –ï–°–¢–¨ –ö–¢–û ---
            # –£ –Ω–∞—Å –µ—Å—Ç—å QR (—ç—Ç–æ –≤—Å–µ–≥–¥–∞ –í–µ—Ä—Ö-–ü—Ä–∞–≤–æ, –µ—Å–ª–∏ –ª–∏—Å—Ç –Ω–µ –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç)
            # –ò 3 –∫–≤–∞–¥—Ä–∞—Ç–∞: TL, BL, BR.
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –º–∞—Å—à—Ç–∞–± –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
            qr_center_orig = qr_center * ratio
            
            found_anchors = []
            for a in anchors[:3]: # –ë–µ—Ä–µ–º 3 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–∞
                M = cv2.moments(a)
                if M["m00"] != 0:
                    cX = int((M["m10"] / M["m00"]) * ratio)
                    cY = int((M["m01"] / M["m00"]) * ratio)
                    found_anchors.append([cX, cY])
            
            if len(found_anchors) < 3: return None, None
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º: 
            # 1. –°—á–∏—Ç–∞–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç QR –∫–æ–¥–∞ –¥–æ –∫–∞–∂–¥–æ–≥–æ —è–∫–æ—Ä—è.
            # TL (–í–µ—Ä—Ö-–õ–µ–≤–æ) - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–ª–∏–∂–µ –≤—Å–µ–≥–æ –ø–æ X –∫ 0 –∏ Y –∫ 0? –ù–µ—Ç, QR —Å–ø—Ä–∞–≤–∞.
            # –°–∞–º—ã–π –¥–∞–ª–µ–∫–∏–π –æ—Ç QR - —ç—Ç–æ BL (–ù–∏–∑-–õ–µ–≤–æ).
            # –ë–ª–∏–∂–∞–π—à–∏–π –ø–æ Y –∫ QR (–Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ) - —ç—Ç–æ TL (–í–µ—Ä—Ö-–õ–µ–≤–æ) (–Ω–µ—Ç, QR —Å–ø—Ä–∞–≤–∞, TL —Å–ª–µ–≤–∞).
            
            # –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º.
            # –ù–æ –ª–∏—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤–µ—Ä–Ω—É—Ç.
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º QR –∫–∞–∫ –æ–ø–æ—Ä–Ω—É—é —Ç–æ—á–∫—É Top-Right.
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ 4 —Ç–æ—á–∫–∏: [A, B, C, QR]
            all_points = np.array(found_anchors + [qr_center_orig.tolist()], dtype="float32")
            
            # –ù–∞–º –Ω—É–∂–Ω–æ —É–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –∏—Ö —Ç–∞–∫, –∫–∞–∫ –≤ DST_PTS: [TL, TR, BR, BL]
            # TR (Top-Right) - —ç—Ç–æ –Ω–∞—à QR –∫–æ–¥.
            
            # –ù–∞–π–¥–µ–º BL (–æ–Ω –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–µ–Ω QR) -> –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç QR
            dists = [np.linalg.norm(np.array(p) - qr_center_orig) for p in found_anchors]
            bl_idx = np.argmax(dists)
            bl_point = found_anchors[bl_idx]
            
            # –û—Å—Ç–∞–ª–∏—Å—å –¥–≤–∞ —è–∫–æ—Ä—è: TL –∏ BR.
            # TL –Ω–∞—Ö–æ–¥–∏—Ç—Å—è "—Å–ª–µ–≤–∞" –æ—Ç –≤–µ–∫—Ç–æ—Ä–∞ BL -> QR ?
            # –ò–ª–∏ –ø—Ä–æ—â–µ: TL –±–ª–∏–∂–µ –∫ QR –ø–æ Y (–µ—Å–ª–∏ –ª–∏—Å—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π), –∞ BR –±–ª–∏–∂–µ –ø–æ X (–æ–Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ —Å QR).
            remaining = [p for i, p in enumerate(found_anchors) if i != bl_idx]
            
            # –í–µ–∫—Ç–æ—Ä BL -> QR
            vec_main = qr_center_orig - np.array(bl_point)
            
            # –í–µ–∫—Ç–æ—Ä BL -> P1
            vec_p1 = np.array(remaining[0]) - np.array(bl_point)
            
            # –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (Cross product), —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —Å–ª–µ–≤–∞ –∏–ª–∏ —Å–ø—Ä–∞–≤–∞ —Ç–æ—á–∫–∞
            cross_prod = np.cross(vec_main, vec_p1) # z-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –≤ 2D
            
            # –ï—Å–ª–∏ –ª–∏—Å—Ç –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ, TL –±—É–¥–µ—Ç "—Å–ª–µ–≤–∞" –æ—Ç –¥–∏–∞–≥–æ–Ω–∞–ª–∏ BL-TR.
            # –ó–Ω–∞—á–∏—Ç, –µ—Å–ª–∏ cross > 0 (–∏–ª–∏ <0 –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏—Å—Ç–µ–º—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç), —ç—Ç–æ TL.
            # –í OpenCV Y –≤–Ω–∏–∑. 
            
            if cross_prod > 0: # P1 —ç—Ç–æ TL (–¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                tl_point = remaining[0]
                br_point = remaining[1]
            else:
                br_point = remaining[0]
                tl_point = remaining[1]

            # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –º–∞—Å—Å–∏–≤ source points –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            src_pts = np.array([
                tl_point,
                qr_center_orig,
                br_point,
                bl_point
            ], dtype="float32")

            # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
            M = cv2.getPerspectiveTransform(src_pts, GraderService.DST_PTS)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º
            warped = cv2.warpPerspective(image, M, (GraderService.A4_WIDTH_PX, GraderService.A4_HEIGHT_PX))
            
            # –î–µ–±–∞–≥
            cv2.imwrite("debug_aligned.jpg", warped)
            
            return warped, "debug_aligned.jpg"

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è: {e}")
            return None, None

    @staticmethod
    def calculate_and_save(student, exam, raw_answers):
        questions = exam.questions.all().order_by('id')
        score = 0
        max_score = len(questions)
        details = {}
        options_map = ["A", "B", "C", "D"]

        for idx, question in enumerate(questions):
            q_num = str(idx + 1)
            student_ans = raw_answers.get(q_num, None)
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            correct_letter = None
            for c_idx, choice in enumerate(question.choices.all().order_by('id')):
                if choice.is_correct and c_idx < 4:
                    correct_letter = options_map[c_idx]
                    break
            
            is_match = (student_ans == correct_letter)
            if is_match: score += 1
            
            details[q_num] = {
                "student": student_ans,
                "correct": correct_letter,
                "is_match": is_match
            }

        percent = (score / max_score) * 100 if max_score > 0 else 0

        result, _ = ExamResult.objects.update_or_create(
            student=student, exam=exam,
            defaults={'score': score, 'max_score': max_score, 'percentage': round(percent, 2), 'details': details}
        )
        return result

    @staticmethod
    def find_qr_code(image):
        detector = cv2.QRCodeDetector()
        data, points, _ = detector.detectAndDecode(image)
        return data, points

    @staticmethod
    def recognize_answers(image, questions_count=20):
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (—É–∂–µ –Ω–∞ –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)

        # 2. –ü–æ–∏—Å–∫ –∫—Ä—É–∂–∫–æ–≤
        cnts, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        question_cnts = []

        # –§–∏–ª—å—Ç—Ä –¥–ª—è –∫—Ä—É–∂–∫–æ–≤ (–ø–æ–¥–≥–æ–Ω—è–µ–º –ø–æ–¥ —Ä–∞–∑–º–µ—Ä—ã –Ω–∞ A4_WIDTH_PX=1240)
        # –ù–∞ –ª–∏—Å—Ç–µ —à–∏—Ä–∏–Ω–æ–π 1240, –∫—Ä—É–∂–æ–∫ –±—É–¥–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 20-25px
        for c in cnts:
            (x, y, w, h) = cv2.boundingRect(c)
            ar = w / float(h)
            
            # –ß—É—Ç—å —Ä–∞—Å—à–∏—Ä–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω, —á—Ç–æ–±—ã –ª–æ–≤–∏—Ç—å –¥–∞–∂–µ –Ω–µ–∏–¥–µ–∞–ª—å–Ω—ã–µ –∫—Ä—É–≥–∏
            if w >= 18 and h >= 18 and w <= 60 and h <= 60 and 0.85 <= ar <= 1.15:
                question_cnts.append(c)

        # 3. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (–°–≤–µ—Ä—Ö—É-–≤–Ω–∏–∑)
        question_cnts = GraderService.sort_contours(question_cnts, method="top-to-bottom")
        
        # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—à–Ω–µ–µ (–µ—Å–ª–∏ –Ω–∞—à–ª–∏ —à—É–º)
        expected = questions_count * 4
        if len(question_cnts) > expected:
            # –ë–µ—Ä–µ–º –Ω–∏–∂–Ω–∏–µ, —Ç–∞–∫ –∫–∞–∫ –≤–æ–ø—Ä–æ—Å—ã –∏–¥—É—Ç –ø–æ—Å–ª–µ —à–∞–ø–∫–∏
            question_cnts = question_cnts[-expected:] 

        results = {}
        debug_img = image.copy()
        options_map = {0: "A", 1: "B", 2: "C", 3: "D"}

        # 4. –ê–Ω–∞–ª–∏–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏
        for (q, i) in enumerate(range(0, len(question_cnts), 4)):
            row_cnts = question_cnts[i:i + 4]
            if len(row_cnts) < 4: continue

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–µ–≤–∞-–Ω–∞–ø—Ä–∞–≤–æ (A, B, C, D)
            row_cnts = GraderService.sort_contours(row_cnts, method="left-to-right")
            
            bubbled = None
            max_pixels = 0

            for (j, c) in enumerate(row_cnts):
                mask = np.zeros(thresh.shape, dtype="uint8")
                cv2.drawContours(mask, [c], -1, 255, -1)
                mask = cv2.bitwise_and(thresh, thresh, mask=mask)
                total = cv2.countNonZero(mask)

                # –ü–æ—Ä–æ–≥ –∑–∞–∫—Ä–∞—à–µ–Ω–Ω–æ—Å—Ç–∏ (–Ω—É–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å, 500 –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ 1240px - –æ–∫)
                if bubbled is None or total > max_pixels:
                    max_pixels = total
                    bubbled = (j, c)

            if bubbled and max_pixels > 550: # –ü–æ–¥–Ω—è–ª –ø–æ—Ä–æ–≥, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ—á–∫–∏
                idx, best_cnt = bubbled
                results[str(q + 1)] = options_map[idx]
                # –†–∏—Å—É–µ–º –∑–µ–ª–µ–Ω—ã–π –∫—Ä—É–∂–æ–∫ –≤–æ–∫—Ä—É–≥ –æ—Ç–≤–µ—Ç–∞
                cv2.drawContours(debug_img, [best_cnt], -1, (0, 255, 0), 4)
            else:
                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω, —Ä–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω—ã–π
                cv2.drawContours(debug_img, row_cnts, -1, (0, 0, 255), 1)

        cv2.imwrite("debug_scan_result.jpg", debug_img)
        return results, "debug_scan_result.jpg"

    @staticmethod
    def sort_contours(cnts, method="left-to-right"):
        if not cnts: return []
        reverse = False
        i = 0
        if method == "top-to-bottom" or method == "bottom-to-top": i = 1
        if method == "right-to-left" or method == "bottom-to-top": reverse = True
        
        boundingBoxes = [cv2.boundingRect(c) for c in cnts]
        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes), key=lambda b: b[1][i], reverse=reverse))
        return cnts